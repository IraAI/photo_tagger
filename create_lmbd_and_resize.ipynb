{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sam/photo_taggers\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random as r\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "image_dir = os.path.abspath('image_data/images')\n",
    "root_dir  = os.path.abspath('.')\n",
    "image_data_dir = os.path.abspath('image_data')\n",
    "print root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_height = 256\n",
    "img_width  = 256\n",
    "\n",
    "image_list = pd.read_csv(os.path.join(root_dir,'actions.csv'))\n",
    "#image_list.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(112)\n",
    "#help(image_list.dropna)\n",
    "image_list_clean = image_list.dropna()\n",
    "#image_list_clean.head(20)\n",
    "image_list_shuffle = image_list_clean.reindex(np.random.permutation(image_list_clean.index))\n",
    "# print(image_list_shuffle.head(20))\n",
    "\n",
    "#print(image_list_shuffle[image_list_shuffle.img == '029122914.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "/home/sam/photo_taggers/image_data/val/064496377.jpg\n",
      "/home/sam/photo_taggers/image_data/val/041776067.jpg\n",
      "/home/sam/photo_taggers/image_data/val/000678817.jpg\n",
      "/home/sam/photo_taggers/image_data/val/010357657.jpg\n",
      "/home/sam/photo_taggers/image_data/val/052910327.jpg\n",
      "/home/sam/photo_taggers/image_data/val/098631684.jpg\n",
      "/home/sam/photo_taggers/image_data/val/019935013.jpg\n",
      "/home/sam/photo_taggers/image_data/val/024423947.jpg\n",
      "/home/sam/photo_taggers/image_data/val/085913036.jpg\n"
     ]
    }
   ],
   "source": [
    "# we need the iterator for testing and showing progress while running\n",
    "i = 0\n",
    "# this row number seperates the training images from the validation images\n",
    "train_val_sep = int(len(image_list_shuffle)*0.8)\n",
    "\n",
    "# map for image filename and class value\n",
    "f_train = open(os.path.join(image_data_dir, 'train_lst.txt'), 'w')\n",
    "f_val   = open(os.path.join(image_data_dir, 'val_lst.txt'), 'w')\n",
    "\n",
    "# load the dictionary that maps the classes (str) to values (int)\n",
    "with open(os.path.join(root_dir, 'labels_map.pickle'), 'rb') as handle:\n",
    "    class_map = pickle.load(handle)\n",
    "\n",
    "for index, row in image_list_shuffle.iterrows():\n",
    "    # if i < 10 or (i > train_val_sep and i < train_val_sep+10):\n",
    "    if (np.mod(i,1000) == 0):\n",
    "        print(i)\n",
    "    try:   \n",
    "\n",
    "        img = cv2.imread(os.path.join(image_dir, row.img))\n",
    "        img = cv2.resize(img, (img_height, img_width))\n",
    "\n",
    "        # input line for map files see abov\n",
    "        txt_input = row.img + ' ' + str(class_map.get(row.act_class)) + '\\n'\n",
    "\n",
    "        if (i < train_val_sep):\n",
    "            f_train.write(txt_input)\n",
    "            img_target = os.path.join(image_data_dir, 'train', row.img)\n",
    "        else:\n",
    "            f_val.write(txt_input)\n",
    "            img_target = os.path.join(image_data_dir, 'val', row.img)\n",
    "            print(img_target)\n",
    "\n",
    "        # resize and move image into right folder \n",
    "        cv2.imwrite(img_target, img)\n",
    "    except Exception:\n",
    "        print(row.img + ' cannot be resized or some other error')\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "f_train.close()\n",
    "f_val.close()\n",
    "#print(image_list_shuffle.iloc[1:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__iter__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'next']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
